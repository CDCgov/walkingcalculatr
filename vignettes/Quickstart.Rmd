---
title: "Quickstart"
date: '`r paste("First created on April 01, 2023. Updated on", Sys.Date())`'
output:
  html_document: 
    df_print: kable
---

```{r, echo = FALSE}
knitr::opts_knit$set(root.dir = dirname(dirname(rstudioapi::getSourceEditorContext()$path)))
options(scipen=999)
```

To get started with `walkingcalculatr`, the `walkingcalculatr` package must be installed with the following dependencies:
```{r eval = T, warning = F, message=F}
library(walkingcalculatr)
library(dplyr)
library(data.table)
```

Installing `walkingcalculatr` will install several additional packages (dependencies) in turn. Further platform specific installation details and notes can be found under [Installation.Rmd](Installation.Rmd). 
</br>

If data partitioning is required due to memory limitations, steps on data manipulation and partitioning using Spark can be found in [Spark_Overview](Spark_Overview.Rmd). Currently `walkingcalculatr` functions have been tested for partitions < 200 million rows using a 64 Gb Linux machine. 

# Data Prep

Once the `walkingcalculatr` package and its dependencies are installed, the minimal input schema needed for location based services (LBS) data are:

Field | Field Description | R Datatype | Example |
--- | --- | --- | --- |
user | A unique identifier for a given device. Each unique identifier has at least one location (via coordinates) over time.|`character`|123456-ABCD|
unix_time | A 10 or 13 digit UNIX timestamp for a given **userId** position in time. If the timestamp column in the raw LBS data is in another format (e.g., UTC datetime), that timestamp column will need to be converted to UNIX time before running `get_walks`.|`numeric`|1655297278|
latitude | Latitude from set of coordinates in decimal degrees notation. | `numeric` | 40.42229 | 
longitude | Longitude from set of coordinates in decimal degrees notation. | `numeric` | -79.78949 | 
accuracy | Horizontal accuracy value of each GPS ping. For datasets without an accuracy value, create a column of where `accuracy = 0`.

***
## 1. Reading in the Raw LBS Data

For this tutorial, we will be using the sample synthetic LBS dataset attached to the `walkingcalculatr` package, `synthetic_ness_data`. The `synthetic_ness_data` contains exactly the columns we need to extract walks and is synthetically generated, which means it does not contain any real LBS data.

```{r}
# read in synthetic_ness_data
data("synthetic_ness_data")

# investigate the first few rows of data
head(synthetic_ness_data)
```

If your data is within a file path or set of file paths, read your data into a `data.table` depending on the format. For example, a file path containing a parquet would use `arrow::read_parquet()`. 
<br>

If you have a directory containing your raw data files and it is in a `parquet`, `csv`, or `csv.gz` format, you can use [arrow::open_dataset()](https://arrow.apache.org/docs/r/reference/open_dataset.html) to extract the data from all of the files in the directory and make it into a single `data.table`. See [Configuration](Configuration.Rmd) for more information on how to use `arrow::open_dataset()`.

***
## 2. Extracting Walks

Once `synthetic_ness_data` has been loaded, extract the walks from the dataset by putting the  `synthetic_ness_data` column names into the correct variables in `get_walks()`. This step extracts only valid walks from the raw dataset, and adds in extra columns for later metric calculation using `metric_summary()`.
```{r results='hide', message = F}
# Extract walks from LBS data for the first partition. Column names are from your LBS dataset 
extracted_walks <- get_walks(synthetic_ness_data, 
                         user = "id", # ID column name in LBS data
                         unix_time = "unix_timestamp", # UNIX timestamp column name in LBS data
                         latitude = 'latitude', # latitude of ping column name in LBS data
                         longitude = 'longitude', # longitude of ping column name in LBS data
                         accuracy = "horizontal_accuracy", # accuracy column name in LBS data
                         homeDist = 100, # Threshold distance for utilitarian calculation, default is 100m
                         
                         # below are optional variables. Users can change values for the below
                         # variables if needed, but not necessary as the defaults are already
                         # integrated in the get_walks() function. See ?get_walks() for more details
                         
                         am_peak_start = 6, # Start of AM peak hours, function default is 6:00
                         am_peak_end = 10,  # End of AM peak hours, function default is 10:00
                         pm_peak_start = 15, # Start of PM peak hours, function default is 15:00
                         pm_peak_end = 19 # End of PM peak hours, function default is 19:00
                         ) 

# investigate the resulting data.table
head(extracted_walks)
```
```{r echo = F, message=F}
library(kableExtra)
head(extracted_walks) %>%
  kable(format = "html", col.names = colnames(extracted_walks)) %>%
  kable_styling() %>%
  scroll_box(width = "100%")

```
## 3. Extracting Walkable Area Features by Census Tract

To determine those walks within defined "walkable" areas, we
can run the following `walkable_areas()` to get walkable areas from OpenStreetMaps (OSM) for census tracts in __Ness County, KS__.
```{r warning=F, eval = T}
# Download census tract data for a given county, state, and year
county_tracts <- get_county_tracts(county_name = "Ness", 
                         state = "KS", 
                         year = 2021)

# Default OSM walkable features will then be extracted based on the census tract boundaries
county_feat_lst <- default_walkable_area(county_tracts = county_tracts)

# Features are then grouped by census tract GEOID and saved as tract-level shapefiles in the directory
tract_area_lst <- walkable_areas(county_tracts = county_tracts,
                                 feat_lst = county_feat_lst,
                                 quietly = T # if F, then print out walkable area extraction progress for each census tract
                                 )
```
_OPTIONAL_: If you want to replicate the calculations later without refreshing the walkable areas for your county, you can use the `save_walkable_areas()` function to save `tract_area_lst` into the save directory of your choice, then load the `tract_area_lst` from the saved directory using `load_walkable_areas()` like below.

```{r eval = F, echo = T}
# Save the walkable area list for future usage
save_walkable_areas(walkable_area_lst = tract_area_lst,
                    use_save_directory = "/path/to/directory/"
                    )

# Load in saved walkable area list
tract_area_lst <- load_walkable_areas(use_area_directory = "/path/to/directory/")
```

</br>

## 4. Checking if Extracted Walk Trips are in Walkable Areas
Given the walkable shapefiles generated, we can find determine which walks have a defined threshold percentage of pings within walkable areas. When defining walks in walkable areas as walks that have 75% of their pings in the walkable areas found in `walkable_areas()`, the resulting data gives us 568 unique walks.
```{r message=F, eval = T, results='hide'}
# Find whether the walks extracted are within walkable areas
walks_in_walkable <- find_walkable(
  extracted_walk_df = extracted_walks, # extracted walks from get_walks()
  county_tracts = county_tracts, # county tracts from get_county_tracts()
  walkable_area_lst = tract_area_lst, # list of buffered walkable areas
  quietly = T # if F, then print out walk trip mapping progress for each census tract
  ) 

# investigate what the data looks like
head(walks_in_walkable)
```
```{r echo = F, message=F}
head(walks_in_walkable) %>%
  kable(format = "html", col.names = colnames(walks_in_walkable)) %>%
  kable_styling() %>%
  scroll_box(width = "100%")
```
</br>

We can then get a general metric summary of the resulting data. From the below table, you can see that the `total_walks_in_walkable_areas` for Ness County, KS is 568.
```{r eval = T, message = F, warning = F, results='hide'}
county_summary <- metric_summary(walks_in_walkable_df = walks_in_walkable)

print(county_summary)
```
```{r echo = F, message=F}
county_summary %>%
  kable(format = "html", col.names = colnames(county_summary)) %>%
  kable_styling() %>%
  scroll_box(width = "100%")
```
A census tract-level metric summary can also be calculated from the resulting data using `tract_metric_summary()`. Since Ness County only has one census tract, the results are less interesting. However, we can use the `san_francisco_walks` data, which has already been mapped to walkable areas, to see what the census tract-level metric summary of the census tracts of __San Francisco County, CA__ looks like.

```{r eval = T, message = F, warning = F, results='hide'}
# load in pre-mapped walks for San Francisco County
data(san_francisco_walks)

# calculate metric summary for each census tract in San Francisco County
tract_summary <- tract_metric_summary(walks_in_walkable_df = san_francisco_walks)

# display metrics from the first few census tracts
head(tract_summary)
```
```{r echo = F, message=F}
head(tract_summary) %>%
  kable(format = "html", col.names = colnames(tract_summary)) %>%
  kable_styling() %>%
  scroll_box(width = "100%")
```

